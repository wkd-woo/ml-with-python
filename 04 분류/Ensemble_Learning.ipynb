{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ensemble-Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1xyjiLD0doW6iukRhqVg1Y3WC-QbBA8I2",
      "authorship_tag": "ABX9TyOLF5zuuGrVYxTzx4DoaZCP"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAykZ5eE-Bjs"
      },
      "source": [
        "## 앙상블 학습 개요\n",
        "\n",
        "`앙상블 학습(Ensemble Learning)` 을 통한 분류는 여러 개의 분류기(Classifier)를 생성하고 그 예측을 결합함으로써 보다 정확한 최종 예측을 도출하는 기법을 말한다.\n",
        "\n",
        "<br>\n",
        "어려운 문제의 결론을 내기 위해 여러 명의 전문가로 위원회를 구성해 다양한 의견을 수렴하고 결정하듯이 앙상블 학습의 목표는 다양한 분류기의 예측 결과를 결합함으로써 단일 분류기보다 신뢰성이 높은 예측값을 얻는 것이다.\n",
        "\n",
        "> *집단 지성*\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "이미지, 영상, 음성 등의 비정형 데이터의 분류는 딥러닝이 뛰어난 성능을 보이고 있지만, 대부분의 **정형 데이터 분류 시에는 앙상블이 뛰어난 성능**을 나타내고 있다.\n",
        "\n",
        "앙상블 알고리즘의 대표격인 랜덤 포레스트와 그래디언트 부스팅을 뛰어넘는 새로운 알고리즘의 개발이 가속화되었다.\n",
        "\n",
        "데이터 과학자들이 기량을 겨루는 오픈 플랫폼인 캐글(Kaggle)에서 '매력적인 솔루션'으로 불리는 XGBoost, 그리고 XGBoost와 유사한 에측 성능을 가지면서도 훨씬 빠른 수행 속도를 가진 LightBGM, 여러가지 모델의 결과를 기반으로 메타 모델을 수립하는 스태킹(Stacking)을 포함해 다양한 유형의 앙상블 알고리즘이 머신러닝의 선도 알고리즘으로 인기를 모으고 있다.\n",
        "\n",
        "XGboost, LightBGM과 같은 최신의 앙상블 모델 한두 개만 잘 알고 잇어도 정형 데이터의 분류나 회귀 분야에서 예측 성능이 매우 뛰어난 모델을 만들 수 있다.\n",
        "\n",
        "그만큼 쉽고 편하면서도 강력한 성능을 보유하고 있는 것이 바로 앙상블 학습의 특징이다.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SP4SUWqg_7AE"
      },
      "source": [
        "\n",
        "앙상블 학습의 유형은 전통적으로 보팅(Voting), 배깅(Bagging), 부스팅(Boosting)의 세 가지로 나눌 수 있으며, 이외에도 스태킹을 포함한 다양한 앙상블 방법이 있다.\n",
        "\n",
        "`보팅`과 `배깅`은 여러 개의 분류기가 투표를 통해 최종 예측 결과를 결정하는 방식이다.   \n",
        "보팅과 배깅의 다른 점은 \n",
        "\n",
        "`보팅`의 경우 일반적으로 *서로 다른 알고리즘을 가진 분류기를 결합* 하는 것이고,\n",
        "\n",
        "`배깅`의 경우 각각의 *분류기가 모두 같은 유형의 알고리즘 기반이지만,    \n",
        "데이터 샘플링을 서로 다르게 가져가면서 학습을 수행* 해 보팅을 수행하는 것이다.\n",
        "\n",
        "대표적인 배깅 방식이 바로 랜덤 포레스트 알고리즘이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uGdY0wIBw4d"
      },
      "source": [
        ">\n",
        "> 보팅 : 같은 데이터 세트, 서로 다른 알고리즘\n",
        ">\n",
        "> 배깅 : 서로 다른 데이터 세트, 같은 알고리즘"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bolHKi9tCAqS"
      },
      "source": [
        "\n",
        "부스팅은 여러 개의 분류기가 순차적으로 학습을 수행하되, 앞에서 학습한 분류기가 예측이 틀린 데이터에 대해서는 올바르게 예측할 수 있도록 다음 분류기에게는 가중치(weight)를 부여하면서 학습과 예측을 진행하는 것이다.\n",
        "\n",
        "계속해서 분류기에게 가중치를 부스팅하면서 학습을 진행하기에 부스팅 방식으로 불린다.   \n",
        "예측 성능이 뛰어나 앙상블 학습을 주도하고 있으며 대표적인 부스팅 모듈로 그래디언트 부스트, XGBoost(eXtra Gradient Boost), LightGBM(Light Gradient Boost) 등이 있다.\n",
        "\n",
        "스태킹은 여러 가지 다른 모델의 예측 결괏값을 다시 학습 데이터로 만들어서 다른 모델(메타 모델)로 재학습시켜 결과를 예측하는 방법이다.\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5pYOVRUFlSR"
      },
      "source": [
        "### 보팅 유형 - **하드 보팅(Hard Voting)**과 **소프트 보팅(Soft Voting)**\n",
        "\n",
        "보팅 방법에는 두 가지가 있다. `하드 보팅`과 `소프트 보팅`이다.\n",
        "\n",
        "하드 보팅을 이용한 분류(Classification)는 다수결 원칙과 비슷하다. 예측한 결괏값들 중 다수의 분류기가 결정한 예측값들을 최종 보팅 결괏값으로 선정하는 것이다.\n",
        "\n",
        "소프트 보팅은 분류기들의 레이블 값 결정 확률을 모두 더하고 이를 평균해서 이들 중 확률이 가장 높은 레이블 값을 최종 보팅 결괏값으로 선정한다.\n",
        "\n",
        "일반적으로 소프트 보팅이 보팅 방법으로 적용된다.\n",
        "\n",
        "**일반적으로** 하드 보팅보다는 소프트 보팅이 예측 성능이 더 좋기 때문.\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-z6C3cRHLzg"
      },
      "source": [
        "### 보팅분류기(Voting Classifier)\n",
        "\n",
        "사이킷런은 보팅 방식의 앙상블을 구현한 VotingClassifier 클래스를 제공하고 있다.\n",
        "\n",
        "보팅 방식의 앙상블을 이용해 위스콘신 유방암 데이터 세트를 예측 분석한다.\n",
        "\n",
        "위스콘신 유방암 데이터 세트는 유방암의 악성종양, 양성종양 여부를 결정하는 이진 분류 데이터 세트이며, 종양의 크기, 모양 등의 형태와 관련한 많은 피처를 가지고 있다.\n",
        "\n",
        "<br>\n",
        "로지스틱 회귀와 KNN을 기반으로 보팅 분류기를 만든다. 먼저 필요한 모듈과 데이터를 로딩한 후 위스콘신 데이터 세트를 간략히 살펴본다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofnZwVPO9lv8"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "aO_cFspYIESI",
        "outputId": "83ce6016-ae10-4ef9-fe6d-3a2d8c63abda"
      },
      "source": [
        "cancer = load_breast_cancer()\n",
        "\n",
        "data_df = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
        "data_df.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>radius error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>area error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.8</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.6</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.9</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.8</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.0</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.5</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean radius  mean texture  ...  worst symmetry  worst fractal dimension\n",
              "0        17.99         10.38  ...          0.4601                  0.11890\n",
              "1        20.57         17.77  ...          0.2750                  0.08902\n",
              "2        19.69         21.25  ...          0.3613                  0.08758\n",
              "\n",
              "[3 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2L5HZN4RIPce"
      },
      "source": [
        "\n",
        "로지스틱 회귀와 KNN을 기반으로 하여 소프트 보팅 방식으로 새롭게 보팅 분류기를 만든다.   \n",
        "사이킷런은 VotingClassifier 클래스를 이용해 보팅 분류기를 생성할 수 있다.\n",
        "VotingClassifier 클래스는 주욧 생성 인자로 estimators와 voting 값을 입력 받는다.   \n",
        "\n",
        "estimators는 리스트 값으로 보팅에 사용될 여러 개의 Classifier 객체들을 튜플 형식으로 입력 받으며 voting은 'hard' 시 하드 보팅, 'soft' 시 소프트 보팅 방식을 적용하라는 의미이다. (기본은 'hard')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5RfJPTNIL5K",
        "outputId": "8528a75a-ced8-4a94-ba5e-70dc906b638f"
      },
      "source": [
        "# 개별 모델은 로지스틱 회귀와 KNN\n",
        "lr_clf = LogisticRegression()\n",
        "knn_clf = KNeighborsClassifier(n_neighbors=8)\n",
        "\n",
        "# 개별 모델을 소프트 보팅 기반의 앙상블 모델로 구현한 분류기\n",
        "vo_clf = VotingClassifier(estimators=[('LR', lr_clf), ('KNN', knn_clf)], voting='soft')\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, test_size=0.2, random_state=156)\n",
        "\n",
        "# VotingClassifier 학습/예측/평가.\n",
        "vo_clf.fit(X_train, y_train)\n",
        "pred = vo_clf.predict(X_test)\n",
        "print('Voting 분류기 정확도: {0:.4f}'.format(accuracy_score(y_test, pred)))\n",
        "\n",
        "# 개별 모델의 학습/예측/평가.\n",
        "classifiers = [lr_clf, knn_clf]\n",
        "for classifier in classifiers:\n",
        "  classifier.fit(X_train, y_train)\n",
        "  pred = classifier.predict(X_test)\n",
        "  class_name = classifier.__class__.__name__\n",
        "  print('{0} 정확도: {1:.4f}'.format(class_name, accuracy_score(y_test, pred)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Voting 분류기 정확도: 0.9474\n",
            "LogisticRegression 정확도: 0.9386\n",
            "KNeighborsClassifier 정확도: 0.9386\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23G4o7KNM3ns"
      },
      "source": [
        "<br>\n",
        "\n",
        "보팅 분류기가 정확도가 조금 높게 나타났는데, 보팅으로 여러 개의 기반 분류기를 결합한다고 해서 무조건 기반 분류기보다 예측 성능이 향상되진느 않는다.   \n",
        "데이터의 특성과 분포 등 다양한 요건에 따라 오히려 기반 분류기 중 가장 좋은 분류기의 성능이 보팅했을 때보다 나을 수도 있다.\n",
        "\n",
        "그럼에도 불구하고 지금 소개하는 보팅을 포함해 배깅과 부스팅 등의 앙상블 방법은 전반적으로 다른 단일 ML 알고리즘보다 뛰어난 예측 성능을 가지는 경우가 많다.\n",
        "\n",
        "고정된 데이터 세트에서 단일 ML 알고리즘이 뛰어난 예측 성능을 발휘하더도 현실 세계는 다양한 변수와 예측이 어려운 규칙으로 구성돼있다.\n",
        "\n",
        "다양한 관점을 가진 알고리즘이 서로 결합해 더 나은 성능을 실제 환경에서 이끌어 낼 수 있다.\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "ML 모델의 성능은 이렇게 다양한 테스트 데이터에 의해 검증되므로 어떻게 높은 유연성을 가지고 현실에 대처할 수 있는가가 중요한 ML 모델의 평가 요소가 된다.\n",
        "\n",
        "이러한 관점에서 편향-분산 트레이드오프는 ML 모델이 극복해야 할 중요한 과제이다.\n",
        "\n",
        "보팅과 스태킹 등은 서로 다른 알고리즘을 기반으로 하고 있지만, 배깅과 부스팅은 대부분 결정 트리 알고리즘을 기반으로 한다.\n",
        "\n",
        "결정 트리 알고리즘은 쉽고 직관적인 분류 기준을 가지고 있지만 정확한 예측을 위해 학습 데이터의 예외 상황에 집착한 나머지 오히려 과적합이 발생해 실제 테스트 데이터에서 예측 성능이 떨어지는 현사이 발생하기 쉽다고 앞에서 말하였다.\n",
        "\n",
        "하지만 앙상블 학습에서는 이 같은 결정 트리 알고리즘의 단점을 수십~수천 개의 매우 많은 분류기를 결합해 다양한 상황을 학습하게 함으로써 극복하고 있다.\n",
        "\n",
        "결정 트리 알고리즘의 장점은 그대로 취하고 단점은 보완하면서 편향-분산 트레이드오프의 효과를 극대활할 수 있다는 것이다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSKR1eJeIsQl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}