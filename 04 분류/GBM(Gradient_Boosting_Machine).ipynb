{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GBM(Gradient-Boosting-Machine).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1fSzyo2xJWJBNZ8yJuggQqYmdYxzJGWbO",
      "authorship_tag": "ABX9TyNOlW7GJ3ymIxialaFVevF8"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbkmd-fiF5--"
      },
      "source": [
        "## Grandien Boosting Machine\n",
        "### GBM의 개요 및 실습\n",
        "\n",
        "부스팅 알고리즘은 여러 개의 약한 학습기(weak learner)를 순차적으로 학습-예측하면서 잘못 예측한 데이터에 가중치 부여를 통해 오류를 개선해 나가면서 학습하는 방식이다.\n",
        "\n",
        "부스팅의 대표적인 구현은 AdaBoost(Adaptive boosting)와 그래디언트 부스트가 있다.\n",
        "\n",
        "에이다 부스트(AdaBoost)는 오류 데이터에 가중치를 부여하면서 부스팅을 수행하는 대표적인 알고리즘이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtMm1ebOIpUd"
      },
      "source": [
        "GBM(Gradient Boost Machine)도 에이다부스트와 유사하나, 가중치 업데이트를 경사 하강법(Gradient Descent)을 이용하는 것이 큰 차이이다.\n",
        "\n",
        "오류 값은 `실제 값 - 예측값` 이다.\n",
        "\n",
        "분류의 실제 결괏값을 y, 피처를 x1, x2, ... , xn, 그리고 이 피처에 기반한 예측 함수를 F(x) 함수라고 하면 `오류식 h(x) = y - F(x)`이 된다.\n",
        "\n",
        "이 오류식 h(x) = y - F(x)를 최소화하는 방향성을 가지고 반복적으로 가중치 값을 업데이트 하는 것이 경사 하강법(Gradient Descent)이다.\n",
        "\n",
        "이 `경사 하강법`은 머신러닝에서 중요한 기법 중 하나이다.\n",
        "\n",
        "다음 장에서 '회귀'를 다룰 때 경사 하강법에 대해 더 알아보도록 하고,\n",
        "\n",
        "여기서는 **'반복 수행을 통해 오류를 최소화 할 수 있도록 가중치의 업데이트 값을 도출하는 기법'** 정도로만 이해하자.\n",
        "\n",
        "GBM은 CART 기반의 다른 알고리즘과 마찬가지로 분류는 물론이고, 회귀도 가능하다.\n",
        "\n",
        "사이킷런은 GBM 기반의 분류를 위해서 GradientBoostingClassifier 클래스를 제공한다.\n",
        "\n",
        "사이킷런의 GBM을 이용해 사용자 행동 데이터 세트를 측정한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vikQuMkXIKho"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import time\n",
        "import warnings\n",
        "import pandas as pd\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cqk7VPavFrQ-",
        "outputId": "8d499c00-8fd6-4ebf-89f2-302e42ec7bd0"
      },
      "source": [
        "# features.txt 파일에는 피처 이름 index와 피처명이 공백으로 분리되어 있음. 이를 DataFrame으로 로드.\n",
        "feature_name_df = pd.read_csv('/content/drive/MyDrive/파이썬 머신러닝 완벽 가이드/04 분류/human_activity/features.txt', sep='\\s+', \n",
        "                              header=None, names=['column_index', 'column_name'])\n",
        "\n",
        "# 피처명 index를 제거하고, 피처명만 리스트 객체로 생성한 뒤 샘플로 10개만 추출\n",
        "feature_name = feature_name_df.iloc[:, 1].values.tolist()\n",
        "print('전체 피처명에서 10개만 추출:', feature_name[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 피처명에서 10개만 추출: ['tBodyAcc-mean()-X', 'tBodyAcc-mean()-Y', 'tBodyAcc-mean()-Z', 'tBodyAcc-std()-X', 'tBodyAcc-std()-Y', 'tBodyAcc-std()-Z', 'tBodyAcc-mad()-X', 'tBodyAcc-mad()-Y', 'tBodyAcc-mad()-Z', 'tBodyAcc-max()-X']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "61tVEl3BFs6N",
        "outputId": "95b3f207-4ca7-455a-9a4c-e7f1b968d6f4"
      },
      "source": [
        "feature_dup_df = feature_name_df.groupby('column_name').count()\n",
        "print(feature_dup_df[feature_dup_df['column_index'] > 1].count())\n",
        "feature_dup_df[feature_dup_df['column_index'] > 1].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "column_index    42\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>column_index</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>column_name</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>fBodyAcc-bandsEnergy()-1,16</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fBodyAcc-bandsEnergy()-1,24</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fBodyAcc-bandsEnergy()-1,8</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fBodyAcc-bandsEnergy()-17,24</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fBodyAcc-bandsEnergy()-17,32</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              column_index\n",
              "column_name                               \n",
              "fBodyAcc-bandsEnergy()-1,16              3\n",
              "fBodyAcc-bandsEnergy()-1,24              3\n",
              "fBodyAcc-bandsEnergy()-1,8               3\n",
              "fBodyAcc-bandsEnergy()-17,24             3\n",
              "fBodyAcc-bandsEnergy()-17,32             3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mF2mJ87kFvyb"
      },
      "source": [
        "def get_new_feature_name_df(old_feature_name_df):\n",
        "  feature_dup_df = pd.DataFrame(data=old_feature_name_df.groupby('column_name').cumcount(), columns=['dup_cnt'])\n",
        "  feature_dup_df = feature_dup_df.reset_index()\n",
        "  new_feature_name_df = pd.merge(old_feature_name_df.reset_index(), feature_dup_df, how='outer')\n",
        "  new_feature_name_df['column_name'] = new_feature_name_df[['column_name', 'dup_cnt']].apply(lambda x : x[0]+'_'+str(x[1]) if x[1] > 0 else x[0] , axis=1)\n",
        "  new_feature_name_df = new_feature_name_df.drop(['index'], axis=1)\n",
        "  return new_feature_name_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HY_gEth0FwJs"
      },
      "source": [
        "def get_human_dataset():\n",
        "\n",
        "  # 각 데이터 파일은 공백으로 분리되어 있으므로 read_csv에서 공백 문자를 sep으로 할당.\n",
        "  feature_name_df = pd.read_csv('/content/drive/MyDrive/파이썬 머신러닝 완벽 가이드/04 분류/human_activity/features.txt', sep='\\s+', \n",
        "                              header=None, names=['column_index', 'column_name'])\n",
        "  \n",
        "  #중복된 피처명을 수정하는 get_new_feature_name_df()를 이용, 신규 피처명 DataFrame 생성.\n",
        "  new_feature_name_df = get_new_feature_name_df(feature_name_df)\n",
        "\n",
        "  # DataFrame에 피처명을 칼럼으로 부여하기 위해 리스트 객체로 다시 변환\n",
        "  feature_name = new_feature_name_df.iloc[:, 1].values.tolist()\n",
        "\n",
        "  # 학습 피처 데이터세트와 테스트 피처 데이터를 DataFrame으로 로딩. 칼럼명은 feature_name 적용\n",
        "  X_train = pd.read_csv('/content/drive/MyDrive/파이썬 머신러닝 완벽 가이드/04 분류/human_activity/train/X_train.txt', sep='\\s+', names=feature_name )\n",
        "  X_test = pd.read_csv('/content/drive/MyDrive/파이썬 머신러닝 완벽 가이드/04 분류/human_activity/test/X_test.txt', sep='\\s+', names=feature_name )\n",
        "\n",
        "  # 학습 피처 데이터세트와 테스트 피처 데이터를 DataFrame으로 로딩. 칼럼명은 feature_name 적용\n",
        "  y_train = pd.read_csv('/content/drive/MyDrive/파이썬 머신러닝 완벽 가이드/04 분류/human_activity/train/y_train.txt', sep='\\s+', names=['action'])\n",
        "  y_test = pd.read_csv('/content/drive/MyDrive/파이썬 머신러닝 완벽 가이드/04 분류/human_activity/test/y_test.txt', sep='\\s+', names=['action'])\n",
        "\n",
        "  # 로드된 학습/테스트용 DataFrame을 모두 반환\n",
        "  return X_train, X_test, y_train, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icIb-idbFx5D"
      },
      "source": [
        "X_train, X_test, y_train, y_test = get_human_dataset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUZjwMH1JvZJ",
        "outputId": "119a8485-b072-48d5-941d-2a34edcc9795"
      },
      "source": [
        "# GBM 수행 시간 측정을 위함. 시작 시간 설정.\n",
        "start_time = time.time()\n",
        "\n",
        "gb_clf = GradientBoostingClassifier(random_state=0)\n",
        "gb_clf.fit(X_train, y_train)\n",
        "gb_pred = gb_clf.predict(X_test)\n",
        "gb_accuracy = accuracy_score(y_test, gb_pred)\n",
        "\n",
        "print('GBM 정확도: {0:.4f}'.format(gb_accuracy))\n",
        "print(\"GBM 수행 시간: {0:.1f} 초 \".format(time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GBM 정확도: 0.9386\n",
            "GBM 수행 시간: 815.5 초 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n39CGHinK4fQ"
      },
      "source": [
        "기본 하이퍼 파라미터만으로 93.76%의 예측 정확도로 앞의 랜덤 포레스트보다 나은 예측 성능을 나타냈다.\n",
        "\n",
        "그지 않은 경우도 있겠지만, 일반적으로 GBM이 랜덤 포레스트보다는 예측 성능이 조금 뛰어난 경우가 많다.\n",
        "\n",
        "그러나 수행 시간이 오래 걸리고, 하이퍼 파라미터 튜닝 노력도 더 필요하다.\n",
        "\n",
        "특히 수행 시간 문제는 GBM이 극복해야 할 중요한 과제이다.\n",
        "\n",
        "사이킷런의 GradientBoostingClassifier는 약한 학습기의 순차적인 예측 오류 보정을 통해 학습을 수행하므로 멀티 CPU 코어 시스템을 사용하더라도 병렬 처리가 지원되지 않아서 대용량 데이터의 경우 학습에 매우 많은 시간이 필요하다.\n",
        "\n",
        "반면에 랜덤 포레스트의 경우 상대적으로 빠른 수행 시간을 보장해주기 때문에 더 쉽게 예측 결과를 도출할 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiiLB2vKLgXC"
      },
      "source": [
        "### GBM 하이퍼 파라미터 튜닝\n",
        "\n",
        "GridSearchCV를 이용해 하이퍼 파라미터를 최적화한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jXA2L1DF1Zy"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqPH2FRTMj2e",
        "outputId": "6e6bb1e0-023c-430a-e962-a199d3309862"
      },
      "source": [
        "params = {\n",
        "    'n_estimators':[100, 500],\n",
        "    'learning_rate':[0.05, 0.1]\n",
        "}\n",
        "\n",
        "grid_cv = GridSearchCV(gb_clf, param_grid=params, cv=2, verbose=1)\n",
        "grid_cv.fit(X_train, y_train)\n",
        "print('최적 하이퍼 파라미터:\\n', grid_cv.best_params_)\n",
        "print('최고 예측 정확도: {0:.4f}'.format(grid_cv.best_score_))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed: 82.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "최적 하이퍼 파라미터:\n",
            " {'learning_rate': 0.05, 'n_estimators': 500}\n",
            "최고 예측 정확도: 0.9013\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmltQVVeM9uz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ce32813-919d-43d6-af2d-392d877459c5"
      },
      "source": [
        "# GridSearchCV를 이용해 최적으로 학습된 estimator로 예측 수행.\n",
        "gb_pred = grid_cv.best_estimator_.predict(X_test)\n",
        "gb_accuracy = accuracy_score(y_test, gb_pred)\n",
        "print('GBM 정확도: {0:.4f}'.format(gb_accuracy))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GBM 정확도: 0.9396\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78ik4KdhNRRO"
      },
      "source": [
        "GBM은 과적합에도 강한 뛰어난 예측 성능을 가진 알고리즘이다.\n",
        "\n",
        "하지만 수행 시간이 오래 걸린다는 단점이 있다.\n",
        "\n",
        "GBM이 처음 소개된 이후 많은 알고리즘이 GBM을 기반으로 새롭게 만들어지고 있다.\n",
        "\n",
        "이 중 머신러닝 세계에서 가장 각광을 받고 있는 두 개의 그래디언트 부스팅 기반 ML 패키지는 XGBoost와 LightGBM이다."
      ]
    }
  ]
}