{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch02_05_데이터전처리.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN69KvtRbten2+ubt6DmPKT"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kWWmW6qUest"
      },
      "source": [
        "## 데이터 인코딩\n",
        "\n",
        "머신러닝을 위한 대표적인 인코딩 방식은 `레이블 인코딩(Label encoding)`과 `원-핫 인코딩(One Hot encoding)`이 있다.\n",
        "\n",
        "`레이블 인코딩` 은 카테고리 피처를 코드형 숫자 값으로 변환하는 것이다.\n",
        "\n",
        "<br>\n",
        "\n",
        "`원 핫 인코딩`은 피처 값의 유형에 따라 새로운 피처를 추가해 고유 값에 해당하는 칼럼에만 1을 표시하고 나머지 칼럼에는 0을 표시한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mA9W5uWITRNF"
      },
      "source": [
        "### 레이블 인코딩\n",
        "\n",
        "사이킷런의 레이블 인코딩(Label encoding)은 LabelEncoder 클래스로 구현합니다. LabelEncoder를 객체로 생성한 후 fit()과 transform을 호출해 레이블 인코딩을 수행한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwPBJTrnTmzx"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yb8m-LXBTqta"
      },
      "source": [
        "items = ['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4GdbNqpTyRO",
        "outputId": "64af4a1b-a3af-4e2f-ea80-8396cd9dfb5b"
      },
      "source": [
        "# LabelEncoder를 객체로 생성한 후, fit()과 transform()으로 레이블 인코딩 수행.\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(items)\n",
        "labels = encoder.transform(items)\n",
        "print('인코딩 변환값:', labels)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "인코딩 변환값: [0 1 4 5 3 3 2 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjpAAyWTT-rB",
        "outputId": "0f276e15-9ab4-4003-f434-4d2550b2c2cc"
      },
      "source": [
        "print('인코딩 클래스:', encoder.classes_)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "인코딩 클래스: ['TV' '냉장고' '믹서' '선풍기' '전자레인지' '컴퓨터']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDCQV8ZvULkv",
        "outputId": "fd7a12c1-32d6-43fa-9916-571356f33717"
      },
      "source": [
        "print('디코딩 원본값:', encoder.inverse_transform([4, 5, 2, 0, 1, 1, 3, 3]))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "디코딩 원본값: ['전자레인지' '컴퓨터' '믹서' 'TV' '냉장고' '냉장고' '선풍기' '선풍기']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0mcZE72UMGW"
      },
      "source": [
        "레이블 인코딩은 간단하게 문자열 값을 숫자형 카테고리 값으로 변환한다.\n",
        "\n",
        "하지만 레이블 인코딩이 일괄적인 숫자 값으로 변환이 되면서 몇몇 ML 알고리즘에는 이를 적용할 경우 예측 성능이 떨어지는 경우가 발생할 수 있음.\n",
        "\n",
        "이는 숫자 값의 경우 크고 작음에 대한 특성이 작용하기 때문 -> *가중치 발생*\n",
        "\n",
        "이러한 특성 때문에 레이블 인코딩은 `선형 회귀`와 같은 ML 알고리즘에는 적용하지 않아야 한다.\n",
        "\n",
        "`트리 계열`의 ML 알고리즘은 이러한 숫자의 특성을 반영하지 않으므로 레이블 인코딩도 문제 없다.\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "`원 핫 인코딩(One-Hot Encoding)`은 레이블 인코딩의 이러한 문제점을 해결하기 위한 인코딩 방식"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDV8xAgxUMX9"
      },
      "source": [
        "*원-핫(여러 개의 속성 중 단 한개의 속성만 1로 표시)*\n",
        "\n",
        "원-핫 인코딩은 사이킷런에서 OneHotEncoder 클래스로 쉽게 변환 가능.\n",
        "\n",
        "단, LabelEncoder와 다르게 주의할 점이 있는데   \n",
        "1. OneHotEncder로 변환하기 전에 모든 문자열 값이 숫자로 변환돼야 함\n",
        "2. 입력 값으로 2차원 데이터 필요"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhSupFaoUMsS"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxr_TvISUM9p"
      },
      "source": [
        "items = ['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-iBjPzkUNNF"
      },
      "source": [
        "# 먼저 숫자 값으로 변환을 위해 LabelEncoder로 변환\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(items)\n",
        "labels = encoder.transform(items)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBfyWBZgUNat"
      },
      "source": [
        "# 2차원 데이터로 변환\n",
        "labels = labels.reshape(-1, 1)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pFbPoPWYwo5"
      },
      "source": [
        "# 원-핫 인코딩 적용\n",
        "oh_encoder = OneHotEncoder()\n",
        "oh_encoder.fit(labels)\n",
        "oh_labels = oh_encoder.transform(labels)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y65wDvcVY7Fr",
        "outputId": "762a07c4-6a0a-4d36-980f-bbbad6fb2aee"
      },
      "source": [
        "print('원-핫 인코딩 데이터')\n",
        "print(oh_labels.toarray())\n",
        "print('원-핫 인코딩 데이터 차원')\n",
        "print(oh_labels.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "원-핫 인코딩 데이터\n",
            "[[1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]]\n",
            "원-핫 인코딩 데이터 차원\n",
            "(8, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnq0zWyiZDu8"
      },
      "source": [
        "판다스에 원-핫 인코딩을 더 쉽게 지원하는 API가 있음.\n",
        "\n",
        "get_dummies()를 이용하면 된다.\n",
        "\n",
        "사이킷런의 OneHotEncoder와는 다르게 문자열 카테고리 값을 숫자 형으로 변환할 필요 X"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEr3eauoZTz4"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "3xCdzVNMZVrd",
        "outputId": "cf7ab6ac-4dfa-4bc9-b231-6838b985efdb"
      },
      "source": [
        "df = pd.DataFrame({'item':['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']})\n",
        "\n",
        "pd.get_dummies(df)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>item_TV</th>\n",
              "      <th>item_냉장고</th>\n",
              "      <th>item_믹서</th>\n",
              "      <th>item_선풍기</th>\n",
              "      <th>item_전자레인지</th>\n",
              "      <th>item_컴퓨터</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   item_TV  item_냉장고  item_믹서  item_선풍기  item_전자레인지  item_컴퓨터\n",
              "0        1         0        0         0           0         0\n",
              "1        0         1        0         0           0         0\n",
              "2        0         0        0         0           1         0\n",
              "3        0         0        0         0           0         1\n",
              "4        0         0        0         1           0         0\n",
              "5        0         0        0         1           0         0\n",
              "6        0         0        1         0           0         0\n",
              "7        0         0        1         0           0         0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFNW7J7pZh6e"
      },
      "source": [
        "---\n",
        "\n",
        "## 피처 스케일링과 정규화\n",
        "\n",
        "서로 다른 변수의 값 범위를 일정한 수준으로 맞추는 작업을 `피처 스케일링(feature scaling)`이라고 한다.\n",
        "\n",
        "대표적인 방법으로는 `표준화(Standardization)`와 `정규화(Normalization)가 있다.\n",
        "\n",
        "표준화는 데이터의 피처 각각이 평균이 0이고 분산이 1인 가우시안 정규 분포를 가진 값으로 변환하는 것을 의미.\n",
        "\n",
        "표준화를 통해 변환될 피처 x의 새로운 i번째 데이터를 xi_new고 한다면\n",
        "\n",
        "이 값은 원래 값에서 피처 x의 평균을 뺀 값을 피처 x의 표준편차로 나눈 값으로 계산할 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcAwAa8UZ4-M"
      },
      "source": [
        "<br>\n",
        "\n",
        "일반적으로 `정규화` 는 서로 다른 피처의 크기를 통일하기 위해 크기를 변환해주는 개념이다.\n",
        "\n",
        "<br>\n",
        "\n",
        "예를 들어 피처 A는 거리를 나타내는 변수로서 값이 0 ~ 100KM로 주어지고   \n",
        "피처 B는 금액을 나타내는 속성으로 값이 0 ~ 100,000,000,000원으로 주어진다면\n",
        "\n",
        "이 변수를 동일한 크기 단위로 비교하기 위해 값을 모두 최소 0 ~ 최대 1의 값으로 변환하는 것.\n",
        "\n",
        "> *즉, 개별 데이터의 크기를 모두 똑같은 단위로 변경하는 것이다.*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiqdCJE6Z6hd"
      },
      "source": [
        "---\n",
        "### StandardScaler\n",
        "\n",
        "StandardScaler는 앞서 설명한 표준화를 쉽게 지원하기 위한 클래스이다. 즉, 개별 피처를 평균이 0이고, 분산이 1인 값으로 변환해준다.\n",
        "\n",
        "이렇게 가우시안 정규 분포를 가질 수 있도록 데이터를 변환하는 것은 몇몇 알고리즘에서 매우 중요하다.\n",
        "\n",
        "특히 사이킷런에서 구현한 RBF 커널을 이용하는 서포트 벡터 머신(Support Vetor Machine)이나 선형 회귀(Linear Regression), 로지스틱 회귀(Logistic Regression)는 데이터가 가우시안 분포를 가지고 있다고 가정하고 구현됐기 때문에   \n",
        "사전에 표준화를 적용하는 것은 예측 성능 향상에 중요한 요소가 될 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pal-zb8RZ7DG"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "import pandas as pd"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xptxRzicZ7mE"
      },
      "source": [
        "# 붓꽃 데이터 세트를 로딩하고 DataFrame으로 변환\n",
        "iris = load_iris()\n",
        "iris_data = iris.data\n",
        "iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwtfcDEtZ75s",
        "outputId": "28be798b-78b1-4d03-cbb9-a88faec14b8e"
      },
      "source": [
        "print('feature 들의 평균 값')\n",
        "print(iris_df.mean())\n",
        "print('\\nfeature들의 분산 값')\n",
        "print(iris_df.var())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "feature 들의 평균 값\n",
            "sepal length (cm)    5.843333\n",
            "sepal width (cm)     3.057333\n",
            "petal length (cm)    3.758000\n",
            "petal width (cm)     1.199333\n",
            "dtype: float64\n",
            "\n",
            "feature들의 분산 값\n",
            "sepal length (cm)    0.685694\n",
            "sepal width (cm)     0.189979\n",
            "petal length (cm)    3.116278\n",
            "petal width (cm)     0.581006\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KYFFNR0dnGb"
      },
      "source": [
        "`StandardScaler` 를 이용해 각 피처를 한번에 표준화해 변환한다.\n",
        "\n",
        "StandardScaler 객체를 생성한 후에 fit()과 transform() 메서드에 변환 대상 피처 데이터 세트를 입력하고 호출하면 간단하게 변환 됨.\n",
        "\n",
        "transform()을 호출할 때 스케일 변환된 데이터 세트가 넘파이의 ndarray이므로 이를 DataFrame으로 변환해 평균값과 분산 값을 다시 확인한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqABLPhDeBb3"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2e8wGDfeE7d"
      },
      "source": [
        "# StandardSclaer 객체 생성\n",
        "scaler = StandardScaler()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZ2_up2HeIje"
      },
      "source": [
        "# StandardScaler로 데이터 세트 변환. fit()과 transform() 호출.\n",
        "scaler.fit(iris_df)\n",
        "iris_scaled = scaler.transform(iris_df)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KggLiebIeRSt"
      },
      "source": [
        "# transform() 시 스케일 변환된 데이터 세트가 NumPy ndarray로 반환돼 이를 DataFrame으로 변환\n",
        "iris_df_scaled = pd.DataFrame(data=iris_scaled, columns=iris.feature_names)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6NL2IDQefae",
        "outputId": "4be097eb-e6a0-4be0-b17f-7142b4640f4f"
      },
      "source": [
        "print('feature 들의 평균 값')\n",
        "print(iris_df_scaled.mean())\n",
        "print('feature 들의 분산 값')\n",
        "print(iris_df_scaled.var())"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "feature 들의 평균 값\n",
            "sepal length (cm)   -1.690315e-15\n",
            "sepal width (cm)    -1.842970e-15\n",
            "petal length (cm)   -1.698641e-15\n",
            "petal width (cm)    -1.409243e-15\n",
            "dtype: float64\n",
            "feature 들의 분산 값\n",
            "sepal length (cm)    1.006711\n",
            "sepal width (cm)     1.006711\n",
            "petal length (cm)    1.006711\n",
            "petal width (cm)     1.006711\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UoRruQYe6Gs"
      },
      "source": [
        "모든 칼럼 값의 평균이 0에 아주 가까운 값으로,\n",
        "\n",
        "그리고 분산은 1에 아주 가까운 갑으로 변환됐음을 알 수 있음."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzmHS1miemye"
      },
      "source": [
        "---\n",
        "### MinMaxScaler\n",
        "\n",
        "`MinMaxScaler`는 데이터값을 0과 1사이의 범위 값으로 변환한다(음수 값이 있으면 -1에서 1 값으로 변환한다.)\n",
        "\n",
        "데이터의 분포가 가우시안 분포가 아닐 경우에 Min, Max Scale을 적용해 볼 수 있다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWI1bFKWe4KL"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diPItf4gfFTa"
      },
      "source": [
        "# MinMaxScaler 객체 생성\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# MinMaxScaler로 데이터 세트 변환. fit()과 transform() 호출.\n",
        "scaler.fit(iris_df)\n",
        "iris_scaled = scaler.transform(iris_df)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6r5uHLQfOnY"
      },
      "source": [
        "# transform() 시 스케일 변환된 데이터 세트가 Numpy ndarray로 반환돼 이를 DataFrame으로 변환\n",
        "iris_df_scaled = pd.DataFrame(data=iris_scaled, columns=iris.feature_names)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIeeoAc_fkpI",
        "outputId": "4154bb84-ad79-48a0-a170-4829b6091085"
      },
      "source": [
        "print('feature들의 최솟값')\n",
        "print(iris_df_scaled.min())\n",
        "print('feature들의 최댓값')\n",
        "print(iris_df_scaled.max())"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "feature들의 최솟값\n",
            "sepal length (cm)    0.0\n",
            "sepal width (cm)     0.0\n",
            "petal length (cm)    0.0\n",
            "petal width (cm)     0.0\n",
            "dtype: float64\n",
            "feature들의 최댓값\n",
            "sepal length (cm)    1.0\n",
            "sepal width (cm)     1.0\n",
            "petal length (cm)    1.0\n",
            "petal width (cm)     1.0\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbVaI5ESfvIO"
      },
      "source": [
        "모든 피처에 0에서 1 값으로 변환되는 스케일링이 적용됐음을 볼 수 있음."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOOSMuIPf3tq"
      },
      "source": [
        "---\n",
        "\n",
        "## 학습 데이터와 테스트 데이터의 스케일링 변환 시 유의점\n",
        "\n",
        "StandardScaler나 MinMaxScaler와 같은 Scaler 객체를 이용해 데이터 스케일링 변환 시 fit(), transform(), fit_transform() 메소드를 이용한다.\n",
        "\n",
        "일반적으로 fit()은 데이터 변환을 위한 기준 정보 설정(예를 들어 데이터 세트의 최댓값/최솟값 설정 등)을 적용하며   \n",
        "transform()은 이렇게 설정한 정보를 이용해 데이터를 변환한다.\n",
        "\n",
        "그리고 fit_transform()은 fit()과 transform()을 한번에 적용하는 기능을 수행한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyE1wleKgZgQ"
      },
      "source": [
        "그런데 학습 데이터 세트와 테스트 데이터 세트에 이 fit()과 transform()을 적용할 때 주의가 필요하다.   \n",
        "Scaler 객체를 이용해 학습 데이터 세트로 fit()과 transform()을 적용하면 테스트 데이터 세트로는 다시는 fit()을 수행하지 않고 학습 데이터 세트로 fit()을 수행한 결과를 이용해 transform() 변환을 적용해야 한다는 것이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtU3Svpdgv_q"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffTWJju3g2Wv"
      },
      "source": [
        "# 학습 데이터는 0부터 10까지, 테스트 데이터는 0부터 5까지 값을 가지는 데이터 세트로 생성\n",
        "# Scaler 클래스의 fit(), transform()은 2차원 이상 데이터만 가능하므로 reshape(-1, 1)로 차원 변경\n",
        "train_array = np.arange(0, 11).reshape(-1, 1)\n",
        "test_array = np.arange(0, 6).reshape(-1, 1)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNG8yhZ1hIlQ"
      },
      "source": [
        "# MinMaxScaler 객체에 별도의 feature_range 파라미터 값을 지정하지 않으면 0~1 값으로 변환\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# fit() 하게 되면 train_array 데이터의 최솟값이 0, 최댓값이 10으로 설정.\n",
        "scaler.fit(train_array)\n",
        "\n",
        "# 1/10 scale로 train_array 데이터 변환함. 원본 10->1 로 변환됨.\n",
        "train_scaled = scaler.transform(train_array)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T64dkr79hzJ5",
        "outputId": "e8ca7098-fa3f-4142-d213-cabdf7610301"
      },
      "source": [
        "print('원본 train_array 데이터:', np.round(train_array.reshape(-1), 2))\n",
        "print('Scale 된 train_array 데이터:', np.round(train_scaled.reshape(-1), 2))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "원본 train_array 데이터: [ 0  1  2  3  4  5  6  7  8  9 10]\n",
            "Scale 된 train_array 데이터: [0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjZsHQk-h_8k",
        "outputId": "3e0dea83-c36f-42b3-bec0-a023c638bd08"
      },
      "source": [
        "# MinMaxScaler에 test_array를 fit()하게 되면 원본 데이터의 최솟값이 0, 최댓값이 5로 설정됨\n",
        "scaler.fit(test_array)\n",
        "\n",
        "# 1/5 scale로 test_array를 변환함. 원본 5->1로 변환.\n",
        "test_scaled = scaler.transform(test_array)\n",
        "\n",
        "# test_array의 scale 변환 출력.\n",
        "print('원본 test_array 데이터:', np.round(test_array.reshape(-1), 2))\n",
        "print('Scale 된 test_array 데이터:', np.round(test_scaled.reshape(-1), 2))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "원본 test_array 데이터: [0 1 2 3 4 5]\n",
            "Scale 된 test_array 데이터: [0.  0.2 0.4 0.6 0.8 1. ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaugsvdRitL-"
      },
      "source": [
        "출력 결과에서 학습 데이터와 테스트 데이터의 스케일링이 맞지 않음을 알 수 있다.\n",
        "\n",
        "테스트 데이터의 경우는 최솟값 0, 최댓값 5이므로 1/5로 스케일링 된다.\n",
        "\n",
        "따라서 원본값 1은 0.2로, 원본값 5는 1로 변환이 된다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUCKGxm4jgZw"
      },
      "source": [
        "다음 코드는 테스트 데이터에 fit()을 호출하지 않고 학습 데이터로 fit()을 수행한 MinMaxScaler 객체의 transform()을 이용해 데이터를 변환한다.   \n",
        "출력 결과를 확인해 보면 학습 데이터, 테스트 데이터, 모두 1/10 수준으로 스케일링 되어 1이 0.1로, 5가 0.5로, 학습 데이터, 테스트 데이터 모두 동일하게 변환됐음을 확인할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8H9kJeJjyME"
      },
      "source": [
        "scaler = MinMaxScaler()\n",
        "scaler.fit(train_array)\n",
        "train_scaled = scaler.transform(train_array)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOokpYkuj5BC",
        "outputId": "3ad9e99c-c70b-443f-b7b9-92dfcb297c4a"
      },
      "source": [
        "print('원본 train_array 데이터:', np.round(train_array.reshape(-1), 2))\n",
        "print('Scale 된 train_array 데이터:', np.round(train_scaled.reshape(-1), 2))\n",
        "\n",
        "# test_array에 Scale 변환을 할 때는 반드시 fit()을 호출하지 않고 transform()만으로 변환해야 함.\n",
        "test_scaled = scaler.transform(test_array)\n",
        "print('\\n원본 test_array 데이터:', np.round(test_array.reshape(-1), 2))\n",
        "print('Scale 된 test_array 데이터:', np.round(test_scaled.reshape(-1), 2))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "원본 train_array 데이터: [ 0  1  2  3  4  5  6  7  8  9 10]\n",
            "Scale 된 train_array 데이터: [0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n",
            "\n",
            "원본 test_array 데이터: [0 1 2 3 4 5]\n",
            "Scale 된 test_array 데이터: [0.  0.1 0.2 0.3 0.4 0.5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDoS_1FyoEwU"
      },
      "source": [
        "fit_transform()을 적용할 때도 마찬가지.\n",
        "fit_transform()은 fit()과 transform을 순차적으로 수행하는 메소드이므로 학습 데이터에서는 상관없지만\n",
        "\n",
        "테스트 데이터에서는 절대 사용해서는 안된다.\n",
        "\n",
        "이렇게 학습과 테스트 데이터에 fit()과 transform()을 적용할 때 주의사항이 발생하므로 학습과 테스트 데이터 세트로 분리하기 전에 먼저 전체 데이터 세트에 스케일링을 적용한 뒤   \n",
        "학습과 테스트 데이터 세트로 분리하는 것이 더 바람직하다.\n",
        "\n",
        ">1. 가능하다면 전체 데이터의 스케일링 변환을 적용한 뒤 학습과 테스트 데이터로 분리\n",
        ">2. 1이 여의치 않다면 테스트 데이터 변환 시에는 fit()이나 fit_transform()을 적용하지 않고 학습 데이터로 이미 fit()된 Scaler 객체를 이용해 transform()으로 변환"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1bJcJ76xDr0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}