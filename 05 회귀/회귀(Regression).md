## ⚙ 회귀 소개

`회귀(regression)`는 현대 통계학을 떠받치고 있는 주요 기둥 중 하나이다.

회귀 기반의 분석은 엔지니어링, 의하, 사회과학, 경제학 등의 분야가 발전하는 데 크게 기여해왔다.   
회귀 분석은 유전적 특성을 연구하던 영국의 통계학자 갈톤이 수행한 연구에서 유래했다는 것이 일반론인데,

> 사람의 키는 평균 키로 회귀하려는 경향을 가진다는 자연의 법칙이 있다.

회귀 분석은 데이터 값이 평균과 같은 일정한 값으로 돌아가려는 경향을 이용한 통계학 기법이다.

통계학 용어를 빌리자면 회귀는 여러 개의 독립변수와 한 개의 종속변수 간의 상관관계를 모델링하는 기법을 통칭한다.

예를 들어 아파트의 방 개수, 방 크기, 주변 학군 등 여러 개의 독립변수에 따라 아파트 가격이라는 종속변수가 어떤 관계를 나타내는지를 모델링하고 예측하는 것이다.

머신러닝 관점에서 보면 독립변수는 피처에 해당되며 종속변수는 결정 값이다.

머신러닝 회귀 예측의 핵심은 주어진 피처와 결정 값 데이터 기반에서 학습을 통해 최적의 회귀 계수를 찾아내는 것이다.

회귀는 회귀 계수의 선형/비선형 여부, 독립변수의 개수, 종속변수의 개수에 따라 여러 가지 유형으로 나눌 수 있다.   
회귀에서 가장 중요한 것은 바로 회귀 계수이다.

이 회귀 계수가 선형이냐 아니냐에 따라 선형 회귀와 비선형 회귀로 나눌 수 있다.

그리고 독립변수의 개수가 한 개인지 여러 개인지에 따라 단일 회귀, 다중 회귀로 나뉜다.


| 독립변수 개수 | 회귀 계수의 결합 |
| --------------| ---------------- |
| 1개: 단일회귀 | 선형: 선형 회귀 |
| 여러 개: 다중 회귀 | 비선형: 비선형 회귀 |

<br>

---

<br>

지도학습은 두 가지 유형으로 나뉘는데, 바로 분류와 회귀이다.

이 두 가지 기법의 가장 큰 차이는 분류는 예측값이 카테고리와 같은 이산형 클래스 값이고 회귀는 연속형 숫자 값이라는 것이다.

여러 가지 회귀 중에서 선형 회귀가 가장 많이 사용된다.

선형 회귀는 실제 값과 예측 값의 차이(오류의 제곱 값)를 최소화하는 직선형 회귀선을 최적화하는 방식이다.

선형 회귀 모델은 규제(Regularization) 방법에 따라 다시 별도의 유형으로 나뉠 수 있다.

규제는 일반적인 선형 회귀의 과적합 문제를 해결하기 위해서 회귀 계수에 패널티 값을 적용하는 것을 말한다.

대표적인 선형 회귀 모델은 다음과 같다.

> + **일반 선형 회귀**: 예측값과 실제값의 RSS(Residual Sum of Squares)를 최소화 할 수 있도록 회귀 계수를 최적화하며, 규제(Regularization)를 적용하지 않은 모델이다.
>
> + **릿지(Ridge)**: 릿지 회귀는 선형 회귀에 L2 규제를 추가한 회귀 모델이다. 릿지 회귀는 L2 규제를 적용하는데, L2 규제는 상대적으로 큰 회귀 계수 값의 예측 영향도를 감소시키기 위해서 회귀 계수값을 더 작게 만드는 규제 모델이다.
>
> + **라쏘(Lasso)**: 라쏘 회귀는 선형 회귀에 L1 규제를 적용한 방식이다. L2 규제가 회귀 계수 값의 크기를 줄이는 데 반해, L1 규제는 예측 영향력이 작은 피처의 회귀 계수를 0으로 만들어 회귀 예측 시 피처가 선택되지 않게 하는 것이다. 이러한 특성 때문에 L1 규제는 `피처 선택 기능`으로도 불린다.
>
> + **엘라스틱넷(ElasticNet)**: L2, L1 규제를 함께 결합한 모델이다. 주로 피처가 많은 데이터 세트에서 적용되며, L1 규제로 피처의 개수를 줄임과 동시에 L2 규제로 계수 값의 크기를 조정한다.
>
> + **로지스틱 회귀(Logisitic Regression)**: 로지스틱 회귀는 회귀라는 이름이 붙어 있지만, 사실은 분류에 사용되는 선형 모델이다. 로지스틱 회귀는 매우 강력한 분류 알고리즘으로, 일반적으로 이진 분류뿐만 아니라 희소 영역의 분류, 예를 들어 텍스트 분류와 같은 영역에서 뛰어난 예측 성능을 보인다.
